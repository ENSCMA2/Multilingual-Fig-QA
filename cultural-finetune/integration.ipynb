{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from finetune import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cultural_corpus': 'yo-bm25-10000',\n",
       " 'pretrained_model': 'FacebookAI/xlm-roberta-base',\n",
       " 'corpus_chunk_size': 128,\n",
       " 'wwm_probability': 0.15,\n",
       " 'batch_size': 64}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask token id is 250001 and mask token is <mask>\n",
      "tokenizer max len 512\n",
      "model config: XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"FacebookAI/xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForMultipleChoice were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm_model num param: 278295186\n",
      "mc_model num param: 278044417\n"
     ]
    }
   ],
   "source": [
    "tokenizer = mk_tokenizer(args)\n",
    "mlm_model, mc_model = mk_models(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _:_.\n",
      "pred 1: The cat said _,_.\n",
      "pred 2: The cat said _that_.\n",
      "pred 3: The cat said _:_.\n",
      "pred 4: The cat said _._.\n",
      "pred 5: The cat said _it_.\n",
      "pred 6: The cat said _he_.\n",
      "pred 7: The cat said _\"_.\n",
      "pred 8: The cat said _to_.\n",
      "pred 9: The cat said _..._.\n"
     ]
    }
   ],
   "source": [
    "fill_mask(args, mlm_model, tokenizer, f\"The cat said {tokenizer.decode(tokenizer.mask_token_id)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'hidden_states'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_text = f\"The cat said {tokenizer.decode(tokenizer.mask_token_id)}.\"\n",
    "toy_input = tokenizer(toy_text, return_tensors=\"pt\")\n",
    "mlm_model(**toy_input).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 270/270 [00:00<00:00, 53839.60 examples/s]\n",
      "Map: 100%|██████████| 30/30 [00:00<00:00, 9487.94 examples/s]\n",
      "Map: 100%|██████████| 270/270 [00:00<00:00, 39769.00 examples/s]\n",
      "Map: 100%|██████████| 30/30 [00:00<00:00, 10412.87 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 train example:\n",
      "{'input_ids': [0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 717], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'word_ids': [None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 1, 2, 3, 3, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 1, 2, 2, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 1, 2, 2, None, None, 0, 1, 2, 3, 3, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 1, 2, 2, None, None, 0, 1, 2, 3, 3, None, None, 0, 1, 2, 3, 3, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 1, 2, 2, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0], 'labels': [0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 717]}\n",
      "decoded: <s> Tokenizers are so meow</s><s> The cat said meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> The cat said meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> The cat said meow</s><s> The cat said meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> Tokenizers are so meow</s><s> Tokenizers are so meow</s><s> To\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 16\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_corpus, corpus_mask_collator, corpus_wwm_collator = mk_corpus(args, tokenizer)\n",
    "lm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1094/1094 [00:00<00:00, 22470.51 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figqa data looks like:\n",
      "train: {'labels': 0, 'input_ids': [[0, 1840, 2565, 1902, 70, 90254, 111, 140147, 6664, 5, 2, 2, 1840, 103036, 7, 831, 186, 18822, 71, 5, 2], [0, 1840, 2565, 1902, 70, 90254, 111, 140147, 6664, 5, 2, 2, 1840, 103036, 7, 53418, 186, 63207, 297, 5, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "decoded: ['<s> Her word had the strength of titanium.</s></s> Her promises can be believed.</s>', '<s> Her word had the strength of titanium.</s></s> Her promises cannot be trusted.</s>']\n",
      "dev: {'labels': 0, 'input_ids': [[0, 581, 23040, 1902, 70, 113014, 12741, 7, 111, 10, 27148, 15555, 2, 2, 581, 23040, 509, 4552, 11348, 133, 5, 2], [0, 581, 23040, 1902, 70, 113014, 12741, 7, 111, 10, 27148, 15555, 2, 2, 581, 23040, 509, 4552, 144142, 5, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "decoded: ['<s> The girl had the flightiness of a sparrow</s></s> The girl was very fickle.</s>', '<s> The girl had the flightiness of a sparrow</s></s> The girl was very stable.</s>']\n",
      "test: {'labels': 0, 'input_ids': [[0, 45990, 254, 156, 13689, 1694, 1619, 1777, 685, 2, 2, 45990, 254, 156, 13689, 156, 350, 80550, 2], [0, 45990, 254, 156, 13689, 1694, 1619, 1777, 685, 2, 2, 45990, 254, 156, 13689, 36130, 5, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "decoded: ['<s> hirup kawas kurung batok</s></s> hirup kawas kakekang</s>', '<s> hirup kawas kurung batok</s></s> hirup kawas bebas.</s>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1458\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1094\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_figqa_datasets, figqa_data_collator = mk_figqa_dataset(args, tokenizer)\n",
    "processed_figqa_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLM train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosarium/anaconda3/envs/multi/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"xlmr-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=args['batch_size'],\n",
    "    per_device_eval_batch_size=args['batch_size'],\n",
    "    logging_steps=1,\n",
    "    num_train_epochs=10,\n",
    "    use_cpu=True,\n",
    "    use_mps_device=False,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=mlm_model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_corpus[\"train\"],\n",
    "    eval_dataset=lm_corpus[\"val\"],\n",
    "    data_collator=corpus_mask_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 12.164128303527832,\n",
       " 'eval_runtime': 0.2334,\n",
       " 'eval_samples_per_second': 4.284,\n",
       " 'eval_steps_per_second': 4.284}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FigQA training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = processed_figqa_datasets[\"train\"]\n",
    "eval_dataset = processed_figqa_datasets[\"validation\"]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, collate_fn=figqa_data_collator, batch_size=args['batch_size'])\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=figqa_data_collator, batch_size=args['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(mc_model.parameters(), lr=2e-5)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='linear',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=3,\n",
    "    num_training_steps=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(mc_model, optimizer, train_dataloader, eval_dataloader, lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_steps = 0\n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    model.train()\n",
    "    model, total_loss, completed_steps = train_model(train_dataloader, model, accelerator, optimizer, lr_scheduler, args, completed_steps, checkpointing_steps, progress_bar)\n",
    "\n",
    "    eval_metric = eval_model(model, eval_dataloader, metric, accelerator, epoch, args)\n",
    "\n",
    "    if args[\"with_tracking\"]:\n",
    "        accelerator.log(\n",
    "            {\n",
    "                \"accuracy\": eval_metric,\n",
    "                \"train_loss\": total_loss.item() / len(train_dataloader),\n",
    "                \"epoch\": epoch,\n",
    "                \"step\": completed_steps,\n",
    "            },\n",
    "            step=completed_steps,\n",
    "        )\n",
    "\n",
    "    if args[\"push_to_hub\"] and epoch < args[\"num_train_epochs\"] - 1:\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(\n",
    "            args[\"output_dir\"], is_main_process=accelerator.is_main_process, save_function=accelerator.save\n",
    "        )\n",
    "        if accelerator.is_main_process:\n",
    "            tokenizer.save_pretrained(args[\"output_dir\"])\n",
    "            # repo.push_to_hub(\n",
    "            #     commit_message=f\"Training in progress epoch {epoch}\", blocking=False, auto_lfs_prune=True\n",
    "            # )\n",
    "\n",
    "    if args[\"checkpointing_steps\"] == \"epoch\":\n",
    "        output_dir = f\"epoch_{epoch}\"\n",
    "        if args[\"output_dir\"] is not None:\n",
    "            output_dir = os.path.join(args[\"output_dir\"], output_dir)\n",
    "        accelerator.save_state(output_dir)\n",
    "\n",
    "if args[\"output_dir\"] is not None:\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(\n",
    "        args[\"output_dir\"], is_main_process=accelerator.is_main_process, save_function=accelerator.save\n",
    "    )\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(args[\"output_dir\"])\n",
    "        # if args[\"push_to_hub\"]:\n",
    "        #     repo.push_to_hub(commit_message=\"End of training\", auto_lfs_prune=True)\n",
    "    with open(os.path.join(args[\"output_dir\"], \"all_results.json\"), \"w\") as f:\n",
    "        json.dump({\"eval_accuracy\": eval_metric[\"accuracy\"]}, f)\n",
    "\n",
    "eval_metric[\"accuracy\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
