{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from finetune import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cultural_corpus': 'yo-bm25-10000',\n",
       " 'pretrained_model': 'FacebookAI/xlm-roberta-base',\n",
       " 'corpus_chunk_size': 128,\n",
       " 'wwm_probability': 0.15,\n",
       " 'batch_size': 64}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask token id is 250001 and mask token is <mask>\n",
      "tokenizer max len 512\n",
      "model config: XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"FacebookAI/xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForMultipleChoice were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm_model num param: 278295186\n",
      "mc_model num param: 278044417\n"
     ]
    }
   ],
   "source": [
    "tokenizer = mk_tokenizer(args)\n",
    "mlm_model, mc_model = mk_models(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _:_.\n",
      "pred 1: The cat said _,_.\n",
      "pred 2: The cat said _that_.\n",
      "pred 3: The cat said _:_.\n",
      "pred 4: The cat said _._.\n",
      "pred 5: The cat said _it_.\n",
      "pred 6: The cat said _he_.\n",
      "pred 7: The cat said _\"_.\n",
      "pred 8: The cat said _to_.\n",
      "pred 9: The cat said _..._.\n"
     ]
    }
   ],
   "source": [
    "fill_mask(args, mlm_model, tokenizer, f\"The cat said {tokenizer.decode(tokenizer.mask_token_id)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'hidden_states'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_text = f\"The cat said {tokenizer.decode(tokenizer.mask_token_id)}.\"\n",
    "toy_input = tokenizer(toy_text, return_tensors=\"pt\")\n",
    "mlm_model(**toy_input).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 270/270 [00:00<00:00, 48956.51 examples/s]\n",
      "Map: 100%|██████████| 30/30 [00:00<00:00, 12652.50 examples/s]\n",
      "Map: 100%|██████████| 270/270 [00:00<00:00, 41202.91 examples/s]\n",
      "Map: 100%|██████████| 30/30 [00:00<00:00, 12162.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 train example:\n",
      "{'input_ids': [0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 717], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'word_ids': [None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 1, 2, 3, 3, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 1, 2, 2, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 1, 2, 2, None, None, 0, 1, 2, 3, 3, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 1, 2, 2, None, None, 0, 1, 2, 3, 3, None, None, 0, 1, 2, 3, 3, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 1, 2, 2, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0], 'labels': [0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 717]}\n",
      "decoded: <s> Tokenizers are so meow</s><s> The cat said meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> The cat said meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> The cat said meow</s><s> The cat said meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> Tokenizers are so meow</s><s> Tokenizers are so meow</s><s> To\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 16\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_corpus, corpus_mask_collator, corpus_wwm_collator = mk_corpus(args, tokenizer)\n",
    "lm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4/4 [00:00<00:00, 1599.96 examples/s]\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 292.96 examples/s]\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 370.65 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figqa data looks like:\n",
      "train: {'labels': 0, 'input_ids': [[0, 581, 7515, 2804, 163, 8770, 2, 2, 163, 8770, 2], [0, 581, 7515, 2804, 163, 8770, 2, 2, 4323, 4390, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "decoded: ['<s> The cat said meow</s></s> meow</s>', '<s> The cat said meow</s></s> woof</s>']\n",
      "val: {'labels': 0, 'input_ids': [[0, 581, 7515, 2804, 163, 8770, 2, 2, 163, 8770, 2], [0, 581, 7515, 2804, 163, 8770, 2, 2, 4323, 4390, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "decoded: ['<s> The cat said meow</s></s> meow</s>', '<s> The cat said meow</s></s> woof</s>']\n",
      "test: {'labels': 0, 'input_ids': [[0, 62, 45730, 7515, 7, 1884, 47, 3249, 83, 163, 8770, 2, 2, 163, 8770, 2], [0, 62, 45730, 7515, 7, 1884, 47, 3249, 83, 163, 8770, 2, 2, 4323, 4390, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "decoded: ['<s> A sound cats like to make is meow</s></s> meow</s>', '<s> A sound cats like to make is meow</s></s> woof</s>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_figqa_datasets, figqa_data_collator = mk_figqa_dataset(args, tokenizer)\n",
    "processed_figqa_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLM train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosarium/anaconda3/envs/multi/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"xlmr-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=args['batch_size'],\n",
    "    per_device_eval_batch_size=args['batch_size'],\n",
    "    logging_steps=1,\n",
    "    num_train_epochs=10,\n",
    "    use_cpu=True,\n",
    "    use_mps_device=False,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=mlm_model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_corpus[\"train\"],\n",
    "    eval_dataset=lm_corpus[\"val\"],\n",
    "    data_collator=corpus_mask_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 12.164128303527832,\n",
       " 'eval_runtime': 0.2334,\n",
       " 'eval_samples_per_second': 4.284,\n",
       " 'eval_steps_per_second': 4.284}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FigQA training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = processed_figqa_datasets[\"train\"]\n",
    "eval_dataset = processed_figqa_datasets[\"val\"]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, collate_fn=figqa_data_collator, batch_size=args['batch_size'])\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=figqa_data_collator, batch_size=args['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(mc_model.parameters(), lr=2e-5)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='linear',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=3,\n",
    "    num_training_steps=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(mc_model, optimizer, train_dataloader, eval_dataloader, lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7454, grad_fn=<NllLossBackward0>)\n",
      "epoch 0: {'accuracy': 0.5}\n",
      "{'accuracy': {'accuracy': 0.5}, 'train_loss': 0.7454084157943726, 'epoch': 0, 'step': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7176, grad_fn=<NllLossBackward0>)\n",
      "epoch 1: {'accuracy': 0.5}\n",
      "{'accuracy': {'accuracy': 0.5}, 'train_loss': 0.7176364660263062, 'epoch': 1, 'step': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6876, grad_fn=<NllLossBackward0>)\n",
      "epoch 2: {'accuracy': 0.5}\n",
      "{'accuracy': {'accuracy': 0.5}, 'train_loss': 0.687591016292572, 'epoch': 2, 'step': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7577, grad_fn=<NllLossBackward0>)\n",
      "epoch 3: {'accuracy': 0.5}\n",
      "{'accuracy': {'accuracy': 0.5}, 'train_loss': 0.7576864957809448, 'epoch': 3, 'step': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7270, grad_fn=<NllLossBackward0>)\n",
      "epoch 4: {'accuracy': 0.5}\n",
      "{'accuracy': {'accuracy': 0.5}, 'train_loss': 0.7270153760910034, 'epoch': 4, 'step': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6458, grad_fn=<NllLossBackward0>)\n",
      "epoch 5: {'accuracy': 0.5}\n",
      "{'accuracy': {'accuracy': 0.5}, 'train_loss': 0.6457862854003906, 'epoch': 5, 'step': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7002, grad_fn=<NllLossBackward0>)\n",
      "epoch 6: {'accuracy': 0.5}\n",
      "{'accuracy': {'accuracy': 0.5}, 'train_loss': 0.700184166431427, 'epoch': 6, 'step': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8835, grad_fn=<NllLossBackward0>)\n",
      "epoch 7: {'accuracy': 0.5}\n",
      "{'accuracy': {'accuracy': 0.5}, 'train_loss': 0.8835403919219971, 'epoch': 7, 'step': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6159, grad_fn=<NllLossBackward0>)\n",
      "epoch 8: {'accuracy': 0.5}\n",
      "{'accuracy': {'accuracy': 0.5}, 'train_loss': 0.6159067153930664, 'epoch': 8, 'step': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6657, grad_fn=<NllLossBackward0>)\n",
      "epoch 9: {'accuracy': 0.5}\n",
      "{'accuracy': {'accuracy': 0.5}, 'train_loss': 0.6657137274742126, 'epoch': 9, 'step': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completed_steps = 0\n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    mc_model.train()\n",
    "    mc_model, total_loss, completed_steps = train_model(train_dataloader, mc_model, accelerator, optimizer, lr_scheduler, args, completed_steps, checkpointing_steps=500)\n",
    "    eval_metric = eval_model(mc_model, eval_dataloader, metric, accelerator, epoch, args)\n",
    "\n",
    "    print({\n",
    "        \"accuracy\": eval_metric,\n",
    "        \"train_loss\": total_loss.item() / len(train_dataloader),\n",
    "        \"epoch\": epoch,\n",
    "        \"step\": completed_steps,\n",
    "    })\n",
    "\n",
    "    # if args[\"push_to_hub\"] and epoch < args[\"num_train_epochs\"] - 1:\n",
    "    #     accelerator.wait_for_everyone()\n",
    "    #     unwrapped_model = accelerator.unwrap_model(mc_model)\n",
    "    #     unwrapped_model.save_pretrained(\n",
    "    #         args[\"output_dir\"], is_main_process=accelerator.is_main_process, save_function=accelerator.save\n",
    "    #     )\n",
    "    #     if accelerator.is_main_process:\n",
    "    #         tokenizer.save_pretrained(args[\"output_dir\"])\n",
    "    #         # repo.push_to_hub(\n",
    "    #         #     commit_message=f\"Training in progress epoch {epoch}\", blocking=False, auto_lfs_prune=True\n",
    "    #         # )\n",
    "\n",
    "    # if args[\"checkpointing_steps\"] == \"epoch\":\n",
    "    #     output_dir = f\"epoch_{epoch}\"\n",
    "    #     if args[\"output_dir\"] is not None:\n",
    "    #         output_dir = os.path.join(args[\"output_dir\"], output_dir)\n",
    "    #     accelerator.save_state(output_dir)\n",
    "\n",
    "# if args[\"output_dir\"] is not None:\n",
    "#     accelerator.wait_for_everyone()\n",
    "#     unwrapped_model = accelerator.unwrap_model(mc_model)\n",
    "#     unwrapped_model.save_pretrained(\n",
    "#         args[\"output_dir\"], is_main_process=accelerator.is_main_process, save_function=accelerator.save\n",
    "#     )\n",
    "#     if accelerator.is_main_process:\n",
    "#         tokenizer.save_pretrained(args[\"output_dir\"])\n",
    "#         # if args[\"push_to_hub\"]:\n",
    "#         #     repo.push_to_hub(commit_message=\"End of training\", auto_lfs_prune=True)\n",
    "#     with open(os.path.join(args[\"output_dir\"], \"all_results.json\"), \"w\") as f:\n",
    "#         json.dump({\"eval_accuracy\": eval_metric[\"accuracy\"]}, f)\n",
    "\n",
    "eval_metric[\"accuracy\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
