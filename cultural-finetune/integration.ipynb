{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosarium/anaconda3/envs/multi/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from finetune import *\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cultural_corpus': 'su-bm25-50000',\n",
       " 'corpus_truncate': 500,\n",
       " 'pretrained_model': 'FacebookAI/xlm-roberta-base',\n",
       " 'corpus_chunk_size': 128,\n",
       " 'wwm_probability': 0.15,\n",
       " 'batch_size': 4,\n",
       " 'lang_code': 'su'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask token id is 250001 and mask token is <mask>\n",
      "tokenizer max len 512\n",
      "model config: XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"FacebookAI/xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForMultipleChoice were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm_model num param: 278295186\n",
      "mc_model num param: 278044417\n"
     ]
    }
   ],
   "source": [
    "tokenizer = mk_tokenizer(toy_args)\n",
    "mlm_model, mc_model = mk_models(toy_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _:_.\n",
      "pred 1: The cat said _,_.\n",
      "pred 2: The cat said _that_.\n",
      "pred 3: The cat said _:_.\n",
      "pred 4: The cat said _._.\n",
      "pred 5: The cat said _it_.\n",
      "pred 6: The cat said _he_.\n",
      "pred 7: The cat said _\"_.\n",
      "pred 8: The cat said _to_.\n",
      "pred 9: The cat said _..._.\n"
     ]
    }
   ],
   "source": [
    "fill_mask(toy_args, mlm_model, tokenizer, f\"The cat said {tokenizer.decode(tokenizer.mask_token_id)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'hidden_states'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_text = f\"The cat said {tokenizer.decode(tokenizer.mask_token_id)}.\"\n",
    "toy_input = tokenizer(toy_text, return_tensors=\"pt\")\n",
    "mlm_model(**toy_input).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/378 [00:00<?, ? examples/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Map: 100%|██████████| 378/378 [00:00<00:00, 32261.25 examples/s]\n",
      "Map: 100%|██████████| 42/42 [00:00<00:00, 15223.02 examples/s]\n",
      "Map: 100%|██████████| 378/378 [00:00<00:00, 33931.45 examples/s]\n",
      "Map: 100%|██████████| 42/42 [00:00<00:00, 14507.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 train example:\n",
      "{'input_ids': [0, 18826, 7, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'word_ids': [None, 0, 0, 1, 2, 2, None, None, 0, 1, 2, 3, 3, None, None, 0, 1, 2, 3, 3, None, None, 0, 1, 2, 3, 3, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 1, 2, 2, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 1, 2, 3, 3, None, None, 0, 0, 1, 2, 2, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 0, 1, 2, 2, None, None, 0, 0, 1, 2, 2, None, None, 0, 0, 0, 0, 1, 2, 3, 3, None, None, 0, 1, 2, 3, 3, None, None, 0, 0, 0, 0, 1, 2, 3], 'labels': [0, 18826, 7, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163]}\n",
      "decoded: <s> Cats say meow</s><s> The cat said meow</s><s> The cat said meow</s><s> The cat said meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> Tokenizers are so meow</s><s> The cat said meow</s><s> Cats say meow</s><s> Tokenizers are so meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> Cats say meow</s><s> Tokenizers are so meow</s><s> The cat said meow</s><s> Tokenizers are so me\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 23\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_corpus, corpus_mask_collator, corpus_wwm_collator = mk_corpus(toy_args, tokenizer, toy=True)\n",
    "lm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 80/80 [00:00<00:00, 19910.06 examples/s]\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 1793.20 examples/s]\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 861.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figqa data looks like:\n",
      "train: {'labels': 0, 'input_ids': [[0, 581, 7515, 2804, 163, 8770, 2, 2, 163, 8770, 2], [0, 581, 7515, 2804, 163, 8770, 2, 2, 4323, 4390, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "decoded: ['<s> The cat said meow</s></s> meow</s>', '<s> The cat said meow</s></s> woof</s>']\n",
      "val: {'labels': 0, 'input_ids': [[0, 581, 7515, 2804, 163, 8770, 2, 2, 163, 8770, 2], [0, 581, 7515, 2804, 163, 8770, 2, 2, 4323, 4390, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "decoded: ['<s> The cat said meow</s></s> meow</s>', '<s> The cat said meow</s></s> woof</s>']\n",
      "test: {'labels': 0, 'input_ids': [[0, 62, 45730, 7515, 7, 1884, 47, 3249, 83, 163, 8770, 2, 2, 163, 8770, 2], [0, 62, 45730, 7515, 7, 1884, 47, 3249, 83, 163, 8770, 2, 2, 4323, 4390, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "decoded: ['<s> A sound cats like to make is meow</s></s> meow</s>', '<s> A sound cats like to make is meow</s></s> woof</s>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figqa_datasets, figqa_data_collator = mk_figqa_dataset(toy_args, tokenizer, toy=True)\n",
    "figqa_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLM with Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosarium/anaconda3/envs/multi/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"xlmr-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=toy_args['batch_size'],\n",
    "    per_device_eval_batch_size=toy_args['batch_size'],\n",
    "    logging_steps=1,\n",
    "    num_train_epochs=10,\n",
    "    use_cpu=True,\n",
    "    use_mps_device=False,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=mlm_model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_corpus[\"train\"],\n",
    "    eval_dataset=lm_corpus[\"val\"],\n",
    "    data_collator=corpus_mask_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 405.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 26.20921516418457,\n",
       " 'eval_runtime': 0.3717,\n",
       " 'eval_samples_per_second': 2.69,\n",
       " 'eval_steps_per_second': 2.69}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:11<01:47, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 24.9817, 'grad_norm': 804.8196411132812, 'learning_rate': 0.00045000000000000004, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 10%|█         | 1/10 [00:12<01:47, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.300202369689941, 'eval_runtime': 0.293, 'eval_samples_per_second': 3.413, 'eval_steps_per_second': 3.413, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:23<01:34, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.855, 'grad_norm': 95.8296890258789, 'learning_rate': 0.0004, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 20%|██        | 2/10 [00:24<01:34, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.265312194824219, 'eval_runtime': 0.2862, 'eval_samples_per_second': 3.494, 'eval_steps_per_second': 3.494, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:35<01:21, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.783, 'grad_norm': 35.669010162353516, 'learning_rate': 0.00035, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 30%|███       | 3/10 [00:35<01:21, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.873168468475342, 'eval_runtime': 0.2918, 'eval_samples_per_second': 3.427, 'eval_steps_per_second': 3.427, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:46<01:09, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1409, 'grad_norm': 57.0134162902832, 'learning_rate': 0.0003, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 40%|████      | 4/10 [00:46<01:09, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.003854751586914, 'eval_runtime': 0.2684, 'eval_samples_per_second': 3.726, 'eval_steps_per_second': 3.726, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:57<00:57, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.168, 'grad_norm': 66.0810775756836, 'learning_rate': 0.00025, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 50%|█████     | 5/10 [00:58<00:57, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.64418625831604, 'eval_runtime': 0.2772, 'eval_samples_per_second': 3.608, 'eval_steps_per_second': 3.608, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:09<00:45, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6576, 'grad_norm': 36.099918365478516, 'learning_rate': 0.0002, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 60%|██████    | 6/10 [01:09<00:45, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9957005977630615, 'eval_runtime': 0.2923, 'eval_samples_per_second': 3.421, 'eval_steps_per_second': 3.421, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:21<00:35, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1602, 'grad_norm': 32.6023063659668, 'learning_rate': 0.00015, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 70%|███████   | 7/10 [01:21<00:35, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0624873638153076, 'eval_runtime': 0.278, 'eval_samples_per_second': 3.597, 'eval_steps_per_second': 3.597, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:32<00:23, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2333, 'grad_norm': 33.87591552734375, 'learning_rate': 0.0001, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 80%|████████  | 8/10 [01:32<00:23, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7064595222473145, 'eval_runtime': 0.2804, 'eval_samples_per_second': 3.566, 'eval_steps_per_second': 3.566, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:43<00:11, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8893, 'grad_norm': 21.227737426757812, 'learning_rate': 5e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 90%|█████████ | 9/10 [01:43<00:11, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.72381591796875, 'eval_runtime': 0.2943, 'eval_samples_per_second': 3.398, 'eval_steps_per_second': 3.398, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:54<00:00, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9403, 'grad_norm': 22.08307647705078, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      "100%|██████████| 10/10 [01:54<00:00, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.725783586502075, 'eval_runtime': 0.283, 'eval_samples_per_second': 3.534, 'eval_steps_per_second': 3.534, 'epoch': 10.0}\n",
      "{'train_runtime': 114.9341, 'train_samples_per_second': 1.392, 'train_steps_per_second': 0.087, 'train_loss': 6.580933213233948, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=6.580933213233948, metrics={'train_runtime': 114.9341, 'train_samples_per_second': 1.392, 'train_steps_per_second': 0.087, 'train_loss': 6.580933213233948, 'epoch': 10.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _me_.\n",
      "pred 1: The cat said _ow_.\n",
      "pred 2: The cat said _ken_.\n",
      "pred 3: The cat said _s_.\n",
      "pred 4: The cat said _Cat_.\n",
      "pred 5: The cat said _say_.\n",
      "pred 6: The cat said _said_.\n",
      "pred 7: The cat said _are_.\n",
      "pred 8: The cat said _To_.\n",
      "pred 9: The cat said _The_.\n"
     ]
    }
   ],
   "source": [
    "fill_mask(toy_args, mlm_model, tokenizer, f\"The cat said {tokenizer.decode(tokenizer.mask_token_id)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLM with Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval instance: {'input_ids': [0, 83479, 88441, 28745, 84247, 12, 250001, 92118, 119037, 602, 59387, 172, 2864, 250001, 250001, 250001, 378, 441, 250001, 4450, 139915, 250001, 1301, 1651, 118, 268, 853, 250001, 119037, 250001, 59387, 172, 247134, 1136, 297, 17028, 378, 441, 250001, 4450, 11, 108531, 1301, 1651, 118, 268, 59337, 202, 152, 602, 59387, 172, 2864, 1136, 297, 17028, 3980, 913, 602, 59387, 172, 2864, 1136, 297, 17028, 40708, 15320, 21261, 602, 59387, 172, 2864, 1136, 297, 17028, 5438, 6392, 71581, 10819, 21801, 250001, 161, 103649, 8011, 2301, 54975, 9, 246, 54975, 86566, 166, 1127, 228950, 98866, 21801, 78, 405, 7804, 8011, 250001, 7502, 250001, 343, 7398, 634, 5, 25623, 148163, 76, 11096, 8743, 6295, 250001, 4591, 9048, 81313, 58940, 1410, 127, 5, 18530, 14, 6744, 148163, 75791, 256, 7502, 156], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, 853, -100, -100, -100, -100, -100, -100, 1136, 297, 17028, -100, -100, 3371, -100, 11, 108531, -100, -100, 118, -100, -100, 92118, -100, 602, -100, -100, 2864, -100, -100, -100, -100, -100, 3371, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 71581, -100, -100, 78, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4, -100, -100, -100, -100, -100, -100, 259, -100, 738, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4688, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n",
      "eval instance: <s> Generation Active Science Six:<mask>sensi Novel Si Lamsijan<mask><mask><mask> [C<mask>thi laborator<mask> Asriati] Re<mask> Novel<mask> Lamsi仃 Kaedanan [C<mask>thia Ramadhan Asriati] Judul : Si Lamsijan Kaedanan Carita Si Lamsijan Kaedanan Caritana novel Si Lamsijan Kaedanan teh disaruakeun jeung<mask>kabayan dina dongeng-dogeng urang sunda כניסת atawa jeung si cepot dina<mask>yang<mask>ek purwa. Eta manehna asa pangpit<mask> tapi bodo katotoloyoh. Hiji waktu manehanana hayang ka\n",
      "eval instance: [0, 0, 0, 0, 0, 0, 'Re', 0, 0, 0, 0, 0, 0, 'Ka', 'ed', 'anan', 0, 0, 'yn', 0, 'a', 'Ramadhan', 0, 0, 'ti', 0, 0, 'sensi', 0, 'Si', 0, 0, 'jan', 0, 0, 0, 0, 0, 'yn', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'rua', 0, 0, 'si', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ',', 0, 0, 0, 0, 0, 0, 'wa', 0, 'go', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'erna', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "train instance (before collate): {'input_ids': [0, 14298, 6837, 4, 59771, 14, 6795, 4, 1843, 111168, 86490, 799, 1434, 156, 6987, 42, 45, 63500, 31652, 13, 9723, 6, 58745, 16551, 4733, 1003, 38, 7071, 496, 4, 11075, 11204, 611, 4, 11075, 248, 173295, 162, 117299, 1003, 38, 87, 4615, 7356, 10313, 127, 45, 54643, 400, 597, 14952, 4, 315, 48, 4451, 8753, 6837, 21801, 29083, 14, 6795, 5438, 48, 4451, 40, 11061, 9, 184, 11061, 66, 5, 2022, 21738, 57, 71581, 642, 18551, 315, 85178, 76, 7356, 2835, 215039, 31584, 113297, 228, 22240, 761, 228, 2676, 4353, 26156, 8410, 592, 228, 19668, 3488, 297, 4, 30843, 4, 165947, 34, 4, 166, 2247, 4, 810, 4021, 5, 10315, 67071, 315, 817, 68998, 10819, 48, 93522, 127099, 8753, 6837, 21801, 29083, 14, 6795, 5, 23411, 127], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0, 14298, 6837, 4, 59771, 14, 6795, 4, 1843, 111168, 86490, 799, 1434, 156, 6987, 42, 45, 63500, 31652, 13, 9723, 6, 58745, 16551, 4733, 1003, 38, 7071, 496, 4, 11075, 11204, 611, 4, 11075, 248, 173295, 162, 117299, 1003, 38, 87, 4615, 7356, 10313, 127, 45, 54643, 400, 597, 14952, 4, 315, 48, 4451, 8753, 6837, 21801, 29083, 14, 6795, 5438, 48, 4451, 40, 11061, 9, 184, 11061, 66, 5, 2022, 21738, 57, 71581, 642, 18551, 315, 85178, 76, 7356, 2835, 215039, 31584, 113297, 228, 22240, 761, 228, 2676, 4353, 26156, 8410, 592, 228, 19668, 3488, 297, 4, 30843, 4, 165947, 34, 4, 166, 2247, 4, 810, 4021, 5, 10315, 67071, 315, 817, 68998, 10819, 48, 93522, 127099, 8753, 6837, 21801, 29083, 14, 6795, 5, 23411, 127]}\n",
      "train instance (before collate): <s> Bandrek, Bajigur, Bioskop Tug Nepi ka Saur di Bandung Baheula | Dunia Aleut! April 30, 2020 Mei 16, 2020 / KomunitasAleut! Ieu mah cenah di taun lilikuran, nu dagang bandrek jeung bajigur teh dagang sewang-sewangan. Ampir sarua we ari nu dijualna mah cara ayeuna meh kabeh kukuluban kumplit tea kayaning kulub boled, cau, sampeu, suuk, jagong. Tapi aya nu ngabedakeun dagangan tukang bandrek jeung bajigur. Cenah\n",
      "train instance (before collate): ['<s>', 'Band', 'rek', ',', 'Baj', 'i', 'gur', ',', 'Bi', 'oskop', 'Tug', 'Ne', 'pi', 'ka', 'Sau', 'r', 'di', 'Bandung', 'Bah', 'e', 'ula', '', '|', 'Dunia', 'Ale', 'ut', '!', 'April', '30', ',', '2020', 'Mei', '16', ',', '2020', '/', 'Komunit', 'as', 'Ale', 'ut', '!', 'I', 'eu', 'mah', 'cena', 'h', 'di', 'taun', 'li', 'lik', 'uran', ',', 'nu', 'da', 'gang', 'band', 'rek', 'jeung', 'baj', 'i', 'gur', 'teh', 'da', 'gang', 'se', 'wang', '-', 'se', 'wang', 'an', '.', 'Am', 'pir', 'sa', 'rua', 'we', 'ari', 'nu', 'dijual', 'na', 'mah', 'cara', 'ayeuna', 'meh', 'kabeh', 'ku', 'kulu', 'ban', 'ku', 'mp', 'lit', 'tea', 'kaya', 'ning', 'ku', 'lub', 'bol', 'ed', ',', 'cau', ',', 'sampe', 'u', ',', 'su', 'uk', ',', 'jag', 'ong', '.', 'Tapi', 'aya', 'nu', 'nga', 'beda', 'keun', 'da', 'gangan', 'tukang', 'band', 'rek', 'jeung', 'baj', 'i', 'gur', '.', 'Cena', 'h']\n"
     ]
    }
   ],
   "source": [
    "corpus_train_dataloader, corpus_val_dataloader = mk_corpus_dataloaders(lm_corpus, corpus_mask_collator, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(mlm_model.parameters(), lr=5e-4)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='linear',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=3,\n",
    "    num_training_steps=30,\n",
    ")\n",
    "# model_name = \"testtest\"\n",
    "# repo_name = get_full_repo_name(model_name)\n",
    "# repo_name\n",
    "# output_dir = model_name\n",
    "# repo = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator1 = Accelerator(cpu=False)\n",
    "mlm_model, optimizer, corpus_train_dataloader, corpus_val_dataloader, lr_scheduler = accelerator1.prepare(mlm_model, optimizer, corpus_train_dataloader, corpus_val_dataloader, lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:21<00:00, 21.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:21<03:16, 21.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 0: Perplexity: 60827416741.042984\n",
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _:_.\n",
      "pred 1: The cat said _,_.\n",
      "pred 2: The cat said _that_.\n",
      "pred 3: The cat said _:_.\n",
      "pred 4: The cat said _._.\n",
      "pred 5: The cat said _it_.\n",
      "pred 6: The cat said _he_.\n",
      "pred 7: The cat said _\"_.\n",
      "pred 8: The cat said _to_.\n",
      "pred 9: The cat said _..._.\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:20<00:00, 20.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:42<02:50, 21.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 1: Perplexity: 455351.87918402714\n",
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _,_.\n",
      "pred 1: The cat said _:_.\n",
      "pred 2: The cat said _._.\n",
      "pred 3: The cat said _that_.\n",
      "pred 4: The cat said _to_.\n",
      "pred 5: The cat said _he_.\n",
      "pred 6: The cat said _it_.\n",
      "pred 7: The cat said _:_.\n",
      "pred 8: The cat said _you_.\n",
      "pred 9: The cat said _\"_.\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:21<00:00, 21.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:04<02:31, 21.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 2: Perplexity: 267.6746430240227\n",
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _,_.\n",
      "pred 1: The cat said _._.\n",
      "pred 2: The cat said _that_.\n",
      "pred 3: The cat said _to_.\n",
      "pred 4: The cat said _me_.\n",
      "pred 5: The cat said _:_.\n",
      "pred 6: The cat said _a_.\n",
      "pred 7: The cat said _you_.\n",
      "pred 8: The cat said _the_.\n",
      "pred 9: The cat said _it_.\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:23<00:00, 23.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:28<02:14, 22.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 3: Perplexity: 133.7124227374177\n",
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _s_.\n",
      "pred 1: The cat said _ow_.\n",
      "pred 2: The cat said _me_.\n",
      "pred 3: The cat said _to_.\n",
      "pred 4: The cat said _._.\n",
      "pred 5: The cat said _the_.\n",
      "pred 6: The cat said _so_.\n",
      "pred 7: The cat said _,_.\n",
      "pred 8: The cat said _are_.\n",
      "pred 9: The cat said _that_.\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:20<00:00, 20.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:50<01:50, 22.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 4: Perplexity: 44.57705552005966\n",
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _me_.\n",
      "pred 1: The cat said _s_.\n",
      "pred 2: The cat said _ow_.\n",
      "pred 3: The cat said _cat_.\n",
      "pred 4: The cat said _so_.\n",
      "pred 5: The cat said _said_.\n",
      "pred 6: The cat said _to_.\n",
      "pred 7: The cat said _are_.\n",
      "pred 8: The cat said _say_.\n",
      "pred 9: The cat said _Me_.\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:26<00:00, 26.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:18<01:36, 24.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 5: Perplexity: 42.654064490981256\n",
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _ow_.\n",
      "pred 1: The cat said _cat_.\n",
      "pred 2: The cat said _s_.\n",
      "pred 3: The cat said _Cat_.\n",
      "pred 4: The cat said _say_.\n",
      "pred 5: The cat said _me_.\n",
      "pred 6: The cat said _so_.\n",
      "pred 7: The cat said _said_.\n",
      "pred 8: The cat said _are_.\n",
      "pred 9: The cat said _ken_.\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:26<00:00, 26.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:45<01:15, 25.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 6: Perplexity: 47.98199169620135\n",
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _say_.\n",
      "pred 1: The cat said _ken_.\n",
      "pred 2: The cat said _s_.\n",
      "pred 3: The cat said _cat_.\n",
      "pred 4: The cat said _Cat_.\n",
      "pred 5: The cat said _said_.\n",
      "pred 6: The cat said _izer_.\n",
      "pred 7: The cat said _so_.\n",
      "pred 8: The cat said _To_.\n",
      "pred 9: The cat said _are_.\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:26<00:00, 26.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [03:12<00:51, 25.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 7: Perplexity: 23.768466292552215\n",
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _izer_.\n",
      "pred 1: The cat said _s_.\n",
      "pred 2: The cat said _me_.\n",
      "pred 3: The cat said _so_.\n",
      "pred 4: The cat said _ken_.\n",
      "pred 5: The cat said _cat_.\n",
      "pred 6: The cat said _Cat_.\n",
      "pred 7: The cat said _To_.\n",
      "pred 8: The cat said _said_.\n",
      "pred 9: The cat said _are_.\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:22<00:00, 22.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:35<00:24, 24.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 8: Perplexity: 19.470916677189024\n",
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _izer_.\n",
      "pred 1: The cat said _me_.\n",
      "pred 2: The cat said _s_.\n",
      "pred 3: The cat said _so_.\n",
      "pred 4: The cat said _ken_.\n",
      "pred 5: The cat said _cat_.\n",
      "pred 6: The cat said _ow_.\n",
      "pred 7: The cat said _said_.\n",
      "pred 8: The cat said _To_.\n",
      "pred 9: The cat said _are_.\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:23<00:00, 23.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:00<00:00, 24.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 9: Perplexity: 18.556267452002295\n",
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _izer_.\n",
      "pred 1: The cat said _me_.\n",
      "pred 2: The cat said _so_.\n",
      "pred 3: The cat said _ow_.\n",
      "pred 4: The cat said _s_.\n",
      "pred 5: The cat said _ken_.\n",
      "pred 6: The cat said _cat_.\n",
      "pred 7: The cat said _Cat_.\n",
      "pred 8: The cat said _To_.\n",
      "pred 9: The cat said _say_.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(10)):\n",
    "    print('training...')\n",
    "    mlm_model.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        outputs = mlm_model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator1.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        # progress_bar.update(1)\n",
    "\n",
    "    print('evaluating...')\n",
    "    mlm_model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = mlm_model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        losses.append(accelerator1.gather(loss.repeat(toy_args['batch_size'])))\n",
    "\n",
    "    losses = torch.cat(losses)\n",
    "    losses = losses[: len(eval_dataset)]\n",
    "    try: perplexity = math.exp(torch.mean(losses))\n",
    "    except OverflowError: perplexity = float(\"inf\")\n",
    "\n",
    "    print(f\">>> Epoch {epoch}: Perplexity: {perplexity}\")\n",
    "    fill_mask(toy_args, mlm_model, tokenizer, f\"The cat said {tokenizer.decode(tokenizer.mask_token_id)}.\")\n",
    "    # Save and upload\n",
    "    # accelerator.wait_for_everyone()\n",
    "    # unwrapped_model = accelerator.unwrap_model(model)\n",
    "    # unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    # if accelerator.is_main_process:\n",
    "    #     tokenizer.save_pretrained(output_dir)\n",
    "    #     repo.push_to_hub(\n",
    "    #         commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FigQA training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = figqa_datasets[\"train\"]\n",
    "eval_dataset = figqa_datasets[\"val\"]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, collate_fn=figqa_data_collator, batch_size=toy_args['batch_size'])\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=figqa_data_collator, batch_size=toy_args['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(mc_model.parameters(), lr=2e-5)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='linear',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=3,\n",
    "    num_training_steps=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accelerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mc_model, optimizer, train_dataloader, eval_dataloader, lr_scheduler \u001b[38;5;241m=\u001b[39m \u001b[43maccelerator\u001b[49m\u001b[38;5;241m.\u001b[39mprepare(mc_model, optimizer, train_dataloader, eval_dataloader, lr_scheduler)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accelerator' is not defined"
     ]
    }
   ],
   "source": [
    "mc_model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(mc_model, optimizer, train_dataloader, eval_dataloader, lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   0,  581, 7515, 2804,  163, 8770,    2,    2,  163, 8770,    2],\n",
       "         [   0,  581, 7515, 2804,  163, 8770,    2,    2, 4323, 4390,    2]]),\n",
       " '<s> The cat said meow</s></s> meow</s>')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "batch['input_ids'][0], tokenizer.decode(batch['input_ids'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:04<00:04,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6984, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7041, grad_fn=<NllLossBackward0>)\n",
      "epoch 0: {'accuracy': 0.75}\n",
      "{'accuracy': {'accuracy': 0.75}, 'train_loss': 0.3520698547363281, 'epoch': 0, 'step': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:03<00:03,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6714, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6595, grad_fn=<NllLossBackward0>)\n",
      "epoch 1: {'accuracy': 1.0}\n",
      "{'accuracy': {'accuracy': 1.0}, 'train_loss': 0.3297400176525116, 'epoch': 1, 'step': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6770, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6631, grad_fn=<NllLossBackward0>)\n",
      "epoch 2: {'accuracy': 0.75}\n",
      "{'accuracy': {'accuracy': 0.75}, 'train_loss': 0.3315522372722626, 'epoch': 2, 'step': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6407, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6217, grad_fn=<NllLossBackward0>)\n",
      "epoch 3: {'accuracy': 0.75}\n",
      "{'accuracy': {'accuracy': 0.75}, 'train_loss': 0.31084996461868286, 'epoch': 3, 'step': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:03<00:03,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6012, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6833, grad_fn=<NllLossBackward0>)\n",
      "epoch 4: {'accuracy': 0.75}\n",
      "{'accuracy': {'accuracy': 0.75}, 'train_loss': 0.341672420501709, 'epoch': 4, 'step': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:03<00:03,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6031, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5491, grad_fn=<NllLossBackward0>)\n",
      "epoch 5: {'accuracy': 0.75}\n",
      "{'accuracy': {'accuracy': 0.75}, 'train_loss': 0.27456343173980713, 'epoch': 5, 'step': 12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:03<00:03,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5815, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5767, grad_fn=<NllLossBackward0>)\n",
      "epoch 6: {'accuracy': 0.75}\n",
      "{'accuracy': {'accuracy': 0.75}, 'train_loss': 0.28835242986679077, 'epoch': 6, 'step': 14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:04<00:04,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5420, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4833, grad_fn=<NllLossBackward0>)\n",
      "epoch 7: {'accuracy': 0.75}\n",
      "{'accuracy': {'accuracy': 0.75}, 'train_loss': 0.24167154729366302, 'epoch': 7, 'step': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:03<00:03,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5684, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5956, grad_fn=<NllLossBackward0>)\n",
      "epoch 8: {'accuracy': 1.0}\n",
      "{'accuracy': {'accuracy': 1.0}, 'train_loss': 0.29778701066970825, 'epoch': 8, 'step': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:03<00:03,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5493, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5318, grad_fn=<NllLossBackward0>)\n",
      "epoch 9: {'accuracy': 1.0}\n",
      "{'accuracy': {'accuracy': 1.0}, 'train_loss': 0.265889436006546, 'epoch': 9, 'step': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completed_steps = 0\n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    mc_model.train()\n",
    "    mc_model, total_loss, completed_steps = train_model(train_dataloader, mc_model, accelerator, optimizer, lr_scheduler, toy_args, completed_steps, checkpointing_steps=500)\n",
    "    eval_metric = eval_model(mc_model, eval_dataloader, metric, accelerator, epoch, toy_args)\n",
    "\n",
    "    print({\n",
    "        \"accuracy\": eval_metric,\n",
    "        \"train_loss\": total_loss.item() / len(train_dataloader),\n",
    "        \"epoch\": epoch,\n",
    "        \"step\": completed_steps,\n",
    "    })\n",
    "\n",
    "    if False:\n",
    "        if toy_args[\"push_to_hub\"] and epoch < toy_args[\"num_train_epochs\"] - 1:\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(mc_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                toy_args[\"output_dir\"], is_main_process=accelerator.is_main_process, save_function=accelerator.save\n",
    "            )\n",
    "            if accelerator.is_main_process:\n",
    "                tokenizer.save_pretrained(toy_args[\"output_dir\"])\n",
    "                # repo.push_to_hub(\n",
    "                #     commit_message=f\"Training in progress epoch {epoch}\", blocking=False, auto_lfs_prune=True\n",
    "                # )\n",
    "\n",
    "        if toy_args[\"checkpointing_steps\"] == \"epoch\":\n",
    "            output_dir = f\"epoch_{epoch}\"\n",
    "            if toy_args[\"output_dir\"] is not None:\n",
    "                output_dir = os.path.join(toy_args[\"output_dir\"], output_dir)\n",
    "            accelerator.save_state(output_dir)\n",
    "\n",
    "if False:\n",
    "    if toy_args[\"output_dir\"] is not None:\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(mc_model)\n",
    "        unwrapped_model.save_pretrained(\n",
    "            toy_args[\"output_dir\"], is_main_process=accelerator.is_main_process, save_function=accelerator.save\n",
    "        )\n",
    "        if accelerator.is_main_process:\n",
    "            tokenizer.save_pretrained(toy_args[\"output_dir\"])\n",
    "            # if args[\"push_to_hub\"]:\n",
    "            #     repo.push_to_hub(commit_message=\"End of training\", auto_lfs_prune=True)\n",
    "        with open(os.path.join(toy_args[\"output_dir\"], \"all_results.json\"), \"w\") as f:\n",
    "            json.dump({\"eval_accuracy\": eval_metric[\"accuracy\"]}, f)\n",
    "\n",
    "eval_metric[\"accuracy\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTaskModel(mlm_model, mc_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _:_.\n",
      "pred 1: The cat said _,_.\n",
      "pred 2: The cat said _that_.\n",
      "pred 3: The cat said _:_.\n",
      "pred 4: The cat said _._.\n",
      "pred 5: The cat said _it_.\n",
      "pred 6: The cat said _he_.\n",
      "pred 7: The cat said _\"_.\n",
      "pred 8: The cat said _to_.\n",
      "pred 9: The cat said _..._.\n"
     ]
    }
   ],
   "source": [
    "model.fill_mask(f\"The cat said {tokenizer.decode(tokenizer.mask_token_id)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== figqa data ===\n",
      "figqa train instance: tensor([[     0,  18826,      7, 137567,   1909,     92,      2,      2,    163,\n",
      "           8770,      2],\n",
      "        [     0,  18826,      7, 137567,   1909,     92,      2,      2,   4323,\n",
      "           4390,      2]]) <s> Cats generally bark</s></s> meow</s>\n",
      "its label: tensor(1)\n",
      "\n",
      "=== cultural data ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 48.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval instance: {'input_ids': [0, 581, 7515, 250001, 163, 250001, 2, 0, 581, 7515, 2804, 250001, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 250001, 7, 5154, 163, 8770, 2, 0, 250001, 217096, 5154, 163, 8770, 2, 0, 581, 7515, 250001, 163, 8770, 2, 0, 18826, 250001, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 170844, 8770, 2, 0, 581, 7515, 250001, 163, 250001, 2, 0, 717, 1098, 52825, 250001, 95607, 221, 163, 8770, 2, 0, 717, 1098, 250001, 7, 250001, 221, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 250001, 8770, 2, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, 2804, -100, 8770, -100, -100, -100, -100, -100, 163, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 18826, -100, -100, -100, -100, -100, -100, 18826, 7, -100, -100, -100, -100, -100, -100, -100, 2804, -100, -100, -100, -100, -100, 7, 5154, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 52825, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 163, -100, -100, -100, -100, -100, 2804, -100, 8770, -100, -100, -100, -100, -100, 7, 621, -100, -100, -100, -100, -100, -100, -100, 52825, -100, 621, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 163, -100, -100, -100]}\n",
      "eval instance: <s> The cat<mask> me<mask></s><s> The cat said<mask>ow</s><s> Cats say meow</s><s><mask>s say meow</s><s><mask> విభజన say meow</s><s> The cat<mask> meow</s><s> Cat<mask> say meow</s><s> The cat said meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> Tokenizers are so Српскојow</s><s> The cat<mask> me<mask></s><s> Tokenizer<mask> ئىچى so meow</s><s> Token<mask>s<mask> so meow</s><s> Tokenizers are so meow</s><s> The cat said<mask>ow</s><s>\n",
      "eval instance: [0, 0, 0, 'said', 0, 'ow', 0, 0, 0, 0, 0, 'me', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'Cat', 0, 0, 0, 0, 0, 0, 'Cat', 's', 0, 0, 0, 0, 0, 0, 0, 'said', 0, 0, 0, 0, 0, 's', 'say', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'izer', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'me', 0, 0, 0, 0, 0, 'said', 0, 'ow', 0, 0, 0, 0, 0, 's', 'are', 0, 0, 0, 0, 0, 0, 0, 'izer', 0, 'are', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'me', 0, 0, 0]\n",
      "\n",
      "train instance (before collate): {'input_ids': [0, 18826, 7, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0, 18826, 7, 5154, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 18826, 7, 5154, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163, 8770, 2, 0, 581, 7515, 2804, 163, 8770, 2, 0, 717, 1098, 52825, 7, 621, 221, 163]}\n",
      "train instance (before collate): <s> Cats say meow</s><s> The cat said meow</s><s> The cat said meow</s><s> The cat said meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> Tokenizers are so meow</s><s> The cat said meow</s><s> Cats say meow</s><s> Tokenizers are so meow</s><s> Tokenizers are so meow</s><s> Cats say meow</s><s> Cats say meow</s><s> Tokenizers are so meow</s><s> The cat said meow</s><s> Tokenizers are so me\n",
      "train instance (before collate): ['<s>', 'Cat', 's', 'say', 'me', 'ow', '</s>', '<s>', 'The', 'cat', 'said', 'me', 'ow', '</s>', '<s>', 'The', 'cat', 'said', 'me', 'ow', '</s>', '<s>', 'The', 'cat', 'said', 'me', 'ow', '</s>', '<s>', 'To', 'ken', 'izer', 's', 'are', 'so', 'me', 'ow', '</s>', '<s>', 'Cat', 's', 'say', 'me', 'ow', '</s>', '<s>', 'To', 'ken', 'izer', 's', 'are', 'so', 'me', 'ow', '</s>', '<s>', 'The', 'cat', 'said', 'me', 'ow', '</s>', '<s>', 'Cat', 's', 'say', 'me', 'ow', '</s>', '<s>', 'To', 'ken', 'izer', 's', 'are', 'so', 'me', 'ow', '</s>', '<s>', 'To', 'ken', 'izer', 's', 'are', 'so', 'me', 'ow', '</s>', '<s>', 'Cat', 's', 'say', 'me', 'ow', '</s>', '<s>', 'Cat', 's', 'say', 'me', 'ow', '</s>', '<s>', 'To', 'ken', 'izer', 's', 'are', 'so', 'me', 'ow', '</s>', '<s>', 'The', 'cat', 'said', 'me', 'ow', '</s>', '<s>', 'To', 'ken', 'izer', 's', 'are', 'so', 'me']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== figqa data ===\")\n",
    "# figqa_datasets, figqa_data_collator = mk_figqa_dataset(toy_args, tokenizer, toy=True)\n",
    "figqa_train_dataloader, figqa_val_dataloader = mk_figqa_dataloaders(figqa_datasets, figqa_data_collator, model.tokenizer, toy_args)\n",
    "\n",
    "print(\"\\n=== cultural data ===\")\n",
    "# lm_corpus, corpus_mask_collator, corpus_wwm_collator = mk_corpus(toy_args, tokenizer, toy=True)\n",
    "corpus_train_dataloader, corpus_val_dataloader = mk_corpus_dataloaders(lm_corpus, corpus_mask_collator, model.tokenizer, toy_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(mlm_model.parameters(), lr=5e-4)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='linear',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=3,\n",
    "    num_training_steps=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator(cpu=False)\n",
    "model, optimizer, lr_scheduler, corpus_train_dataloader, corpus_val_dataloader, figqa_train_dataloader, figqa_val_dataloader = accelerator.prepare(model, optimizer, lr_scheduler, corpus_train_dataloader, corpus_val_dataloader, figqa_train_dataloader, figqa_val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9471, device='mps:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for corpus_batch in corpus_train_dataloader:\n",
    "    mlm_logits, mlm_loss = model.mlm_forward(corpus_batch)\n",
    "    break\n",
    "mlm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6932, device='mps:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for figqa_batch in figqa_train_dataloader: \n",
    "    mc_logits, mc_loss = model.mc_forward(figqa_batch)\n",
    "    break\n",
    "mc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "🏗️ training mlm...\n",
      "🎯 mlm loss:  4.815908432006836\n",
      "🏗️ training figqa...\n",
      "🎯 mc loss:  0.7211445569992065\n",
      "🧪 evaluating mlm...\n",
      "😵‍💫 mlm val perplexity: 77.15788719557149\n",
      "🧪 evaluating figqa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:40<00:40, 40.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🪄 figqa metric: {'accuracy': 1.0}\n",
      "epoch:  1\n",
      "🏗️ training mlm...\n",
      "🎯 mlm loss:  4.592772483825684\n",
      "🏗️ training figqa...\n",
      "🎯 mc loss:  0.6100887656211853\n",
      "🧪 evaluating mlm...\n",
      "😵‍💫 mlm val perplexity: 53.32393834385654\n",
      "🧪 evaluating figqa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:35<00:00, 47.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🪄 figqa metric: {'accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(2)):\n",
    "    print(\"epoch: \", epoch)\n",
    "    \n",
    "    # 1 > train\n",
    "    model.train()\n",
    "    print('🏗️ training mlm...')\n",
    "    for corpus_batch in corpus_train_dataloader:\n",
    "        mlm_logits, mlm_loss = model.mlm_forward(corpus_batch)\n",
    "        print(\"🎯 mlm loss: \", mlm_loss.item())\n",
    "        # accelerator.backward(mlm_loss)\n",
    "        mlm_loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        break\n",
    "    \n",
    "    model.train()\n",
    "    print('🏗️ training figqa...')\n",
    "    for figqa_batch in figqa_train_dataloader:\n",
    "        mc_logits, mc_loss = model.mc_forward(figqa_batch)\n",
    "        print(\"🎯 mc loss: \", mc_loss.item())\n",
    "        # accelerator.backward(mc_loss)\n",
    "        mc_loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        break\n",
    "    \n",
    "    # 2 > validate\n",
    "    model.eval()\n",
    "    print('🧪 evaluating mlm...')\n",
    "    # model.fill_mask(f\"The cat said {tokenizer.decode(tokenizer.mask_token_id)}.\")\n",
    "    mlm_losses = []\n",
    "    for corpus_batch in corpus_val_dataloader:\n",
    "        with torch.no_grad():\n",
    "            mlm_logits, mlm_loss = model.mlm_forward(corpus_batch)\n",
    "        mlm_losses.append(accelerator.gather(mlm_loss.repeat(toy_args['batch_size'])))\n",
    "    mlm_losses = torch.cat(mlm_losses)\n",
    "    mlm_losses = mlm_losses[: len(lm_corpus['val'])]\n",
    "    try: perplexity = math.exp(torch.mean(mlm_losses))\n",
    "    except OverflowError: perplexity = float(\"inf\")\n",
    "    print(f'😵‍💫 mlm val perplexity: {perplexity}')\n",
    "\n",
    "    model.eval()\n",
    "    print('🧪 evaluating figqa...')\n",
    "    figqa_samples_seen = 0\n",
    "    figqa_metric = evaluate.load(\"accuracy\")\n",
    "    for step, figqa_batch in enumerate(figqa_val_dataloader):\n",
    "        with torch.no_grad():\n",
    "            mc_logits, mc_loss = model.mc_forward(figqa_batch)\n",
    "        predictions = mc_logits.argmax(dim=-1)\n",
    "        predictions, references = accelerator.gather((predictions, figqa_batch[\"labels\"]))\n",
    "        # If we are in a multiprocess environment, we're cooked\n",
    "        if accelerator.num_processes > 1: assert(False)\n",
    "        figqa_metric.add_batch(predictions=predictions,references=references,)\n",
    "    eval_figqa_metric = figqa_metric.compute()\n",
    "    print(f'🪄 figqa metric: {eval_figqa_metric}')\n",
    "\n",
    "    \n",
    "    if False:\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "        if accelerator.is_main_process:\n",
    "            tokenizer.save_pretrained(output_dir)\n",
    "            repo.push_to_hub(\n",
    "                commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: The cat said <mask>.\n",
      "pred 0: The cat said _s_.\n",
      "pred 1: The cat said _ken_.\n",
      "pred 2: The cat said _cat_.\n",
      "pred 3: The cat said _me_.\n",
      "pred 4: The cat said _are_.\n",
      "pred 5: The cat said _ow_.\n",
      "pred 6: The cat said _Are_.\n",
      "pred 7: The cat said _say_.\n",
      "pred 8: The cat said _e_.\n",
      "pred 9: The cat said _so_.\n"
     ]
    }
   ],
   "source": [
    "model.fill_mask(f\"The cat said {tokenizer.decode(tokenizer.mask_token_id)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: The cat me<mask>ed and walked away.\n",
      "pred 0: The cat me_s_ed and walked away.\n",
      "pred 1: The cat me_ken_ed and walked away.\n",
      "pred 2: The cat me_cat_ed and walked away.\n",
      "pred 3: The cat me_me_ed and walked away.\n",
      "pred 4: The cat me_are_ed and walked away.\n",
      "pred 5: The cat me_say_ed and walked away.\n",
      "pred 6: The cat me_Are_ed and walked away.\n",
      "pred 7: The cat me_ow_ed and walked away.\n",
      "pred 8: The cat me_said_ed and walked away.\n",
      "pred 9: The cat me_so_ed and walked away.\n"
     ]
    }
   ],
   "source": [
    "model.fill_mask(f\"The cat me{tokenizer.decode(tokenizer.mask_token_id)}ed and walked away.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
