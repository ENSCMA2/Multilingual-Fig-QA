name: Multilingual-FigQA General Sweep
description: none
entity: chaosarium
project: multi
program: main.py
command:
  - ${env}
  - python
  - ${program}
  - "--tags"
  - "sweeping"
  - ${args}
method: bayes
metric:
  name: test/mc_acc
  goal: maximize
parameters:

  pretrained_model:
    value: 'xlm-roberta-base'
  cultural_corpus:
    value: 'yo-bm25-10000'
  lang:
    value: 'yo'
    
  corpus_truncate:
    values: [2000, 4000, 7000]
  corpus_chunk_size:
    values: [32, 64, 128, 256]
  mask_probability:
    values: [0.1, 0.15, 0.2]
  
  num_corpus_epochs:
    values: [1,2,3,4,5]
  num_interleaved_epochs:
    min: 10
    max: 50
    distribution: int_uniform
  num_figqa_epochs:
    min: 20
    max: 100
    distribution: int_uniform
  corpus_lr:
    min: 1e-6
    max: 1e-4
    distribution: uniform
  interleave_lr:
    min: 1e-6
    max: 1e-4
    distribution: uniform
  figqa_lr:
    min: 1e-6
    max: 1e-4
    distribution: uniform
  steps_per_interleaved_epoch:
    min: 50
    max: 200
    distribution: int_uniform
  gradient_accumulation_steps:
    values: [1, 4, 8, 16]

  batch_size:
    value: 32
  mc_loss_weight:
    value: 1.0
  mc_sample_weight:
    min: 0.1
    max: 0.9
    distribution: uniform
  mlm_loss_weight:
    min: 0.1
    max: 2.0
    distribution: uniform
  
  seed:
    value: 0

